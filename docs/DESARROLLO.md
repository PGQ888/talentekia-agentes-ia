archivo# üõ†Ô∏è Gu√≠a de Desarrollo - TalentekIA

Esta gu√≠a est√° dirigida a desarrolladores que deseen contribuir al proyecto TalentekIA o extender su funcionalidad.

## Arquitectura del Sistema

TalentekIA est√° estructurado siguiendo un patr√≥n modular con los siguientes componentes principales:

### 1. Agentes

Los agentes son el n√∫cleo del sistema. Cada agente es una clase Python que hereda de `BaseAgent` y se encarga de realizar una tarea espec√≠fica. Los agentes est√°n ubicados en `src/agents/`.

```
src/agents/
‚îú‚îÄ‚îÄ base_agent.py       # Clase base para todos los agentes
‚îú‚îÄ‚îÄ agent_manager.py    # Gestor centralizado de agentes
‚îú‚îÄ‚îÄ config.py           # Configuraci√≥n espec√≠fica de agentes
‚îú‚îÄ‚îÄ linkedin_agent.py   # Agente para an√°lisis de LinkedIn
‚îî‚îÄ‚îÄ ...                 # Otros agentes espec√≠ficos
```

### 2. Interfaz de Usuario

La interfaz de usuario est√° desarrollada con Streamlit y se encuentra en `src/interface/`.

```
src/interface/
‚îî‚îÄ‚îÄ streamlit_app.py    # Aplicaci√≥n principal de Streamlit
```

### 3. Utilidades

Las funciones y clases de utilidad se encuentran en `src/utils/`.

```
src/utils/
‚îú‚îÄ‚îÄ helpers.py          # Funciones auxiliares generales
‚îú‚îÄ‚îÄ env_loader.py       # Cargador de variables de entorno
‚îú‚îÄ‚îÄ weekly_summary.py   # Generador de res√∫menes semanales
‚îî‚îÄ‚îÄ ...                 # Otras utilidades
```

## Creaci√≥n de un Nuevo Agente

Para crear un nuevo agente, sigue estos pasos:

1. Crea un nuevo archivo en `src/agents/`, por ejemplo `mi_agente.py`
2. Define una clase que herede de `BaseAgent`
3. Implementa los m√©todos requeridos: `run()`, `process_data()` y `generate_report()`
4. Registra el agente en `config/settings.py`

### Ejemplo de un Nuevo Agente

```python
# src/agents/mi_agente.py
from typing import Dict, List, Any, Optional
import pandas as pd
from src.agents.base_agent import BaseAgent

class MiAgente(BaseAgent):
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__("mi_agente", config)
    
    def run(self):
        """M√©todo principal que ejecuta el agente"""
        self.logger.info("Iniciando ejecuci√≥n de MiAgente")
        
        # L√≥gica principal del agente
        data = self._recopilar_datos()
        
        # Procesar los datos
        df = self.process_data(data)
        
        # Generar informe
        report = self.generate_report(df)
        
        # Guardar resultados
        self.save_results(df, report)
        
        return True
    
    def _recopilar_datos(self):
        """M√©todo privado para recopilar datos"""
        # Implementaci√≥n espec√≠fica
        return [{"campo1": "valor1", "campo2": "valor2"}]
    
    def process_data(self, data: List[Dict[str, Any]]):
        """Procesa los datos recopilados"""
        return pd.DataFrame(data)
    
    def generate_report(self, df: pd.DataFrame):
        """Genera un informe basado en los datos procesados"""
        return f"""# Informe de MiAgente
        
## Resumen
        
Se han procesado {len(df)} registros.
        
## Detalles
        
{df.describe().to_markdown()}
        
## Conclusiones
        
Este es un informe de ejemplo generado por MiAgente.
"""

# Funci√≥n para crear una instancia del agente
def create_agent(config=None):
    return MiAgente(config)
```

### Registro del Nuevo Agente

A√±ade la configuraci√≥n de tu agente en `config/settings.py`:

```python
# En la funci√≥n create_default_config()
default_config = {
    # ... configuraci√≥n existente ...
    "agents": {
        # ... otros agentes ...
        "mi_agente": {
            "enabled": True,
            "description": "Descripci√≥n de mi agente personalizado",
            "parameters": {
                "param1": "valor1",
                "param2": "valor2"
            }
        }
    }
}
```

## Integraci√≥n con Servicios Externos

### OpenAI

Para integrar con la API de OpenAI:

```python
from openai import OpenAI
from src.utils.env_loader import EnvLoader

# Obtener la clave API
api_key = EnvLoader().get_api_key("openai")

# Crear cliente
client = OpenAI(api_key=api_key)

# Realizar una llamada a la API
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "Eres un asistente √∫til."},
        {"role": "user", "content": "Analiza estos datos y dame un resumen."}
    ]
)

# Procesar la respuesta
result = response.choices[0].message.content
```

### Anthropic

Para integrar con la API de Anthropic:

```python
from anthropic import Anthropic
from src.utils.env_loader import EnvLoader

# Obtener la clave API
api_key = EnvLoader().get_api_key("anthropic")

# Crear cliente
client = Anthropic(api_key=api_key)

# Realizar una llamada a la API
response = client.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=1000,
    messages=[
        {"role": "user", "content": "Analiza estos datos y dame un resumen."}
    ]
)

# Procesar la respuesta
result = response.content[0].text
```

## Pruebas

Las pruebas se encuentran en el directorio `tests/`. Utilizamos pytest como framework de pruebas.

### Estructura de Pruebas

```
tests/
‚îú‚îÄ‚îÄ conftest.py         # Configuraci√≥n y fixtures para pytest
‚îú‚îÄ‚îÄ test_agents.py      # Pruebas para los agentes
‚îî‚îÄ‚îÄ test_interface.py   # Pruebas para la interfaz
```

### Ejecutar Pruebas

```bash
# Ejecutar todas las pruebas
pytest

# Ejecutar pruebas espec√≠ficas
pytest tests/test_agents.py

# Ejecutar con cobertura
pytest --cov=src tests/
```

## Estilo de C√≥digo

Seguimos las convenciones de estilo PEP 8 para Python. Utilizamos las siguientes herramientas para mantener la calidad del c√≥digo:

- **Black**: Formateador de c√≥digo
- **isort**: Ordenador de importaciones
- **flake8**: Linter de c√≥digo

### Formatear el C√≥digo

```bash
# Usando make
make format

# Manualmente
black src/ tests/
isort src/ tests/
```

### Verificar el Estilo

```bash
# Usando make
make lint

# Manualmente
flake8 src/ tests/
```

## Flujo de Trabajo de Desarrollo

1. **Configurar el entorno de desarrollo**:
   ```bash
   make install-dev
   ```

2. **Crear una rama para tu funcionalidad**:
   ```bash
   git checkout -b feature/mi-funcionalidad
   ```

3. **Implementar cambios y pruebas**

4. **Formatear y verificar el c√≥digo**:
   ```bash
   make format
   make lint
   ```

5. **Ejecutar pruebas**:
   ```bash
   make test
   ```

6. **Commit y push**:
   ```bash
   git add .
   git commit -m "A√±adir mi funcionalidad"
   git push origin feature/mi-funcionalidad
   ```

7. **Crear un Pull Request** en GitHub

## Despliegue

### Despliegue Local

```bash
# Instalar el paquete en modo desarrollo
pip install -e .

# Ejecutar la aplicaci√≥n
talentekia
```

### Despliegue en Servidor

1. Clonar el repositorio en el servidor
2. Instalar dependencias: `pip install -r requirements.txt`
3. Configurar variables de entorno en `.env`
4. Iniciar la aplicaci√≥n con un servidor WSGI como Gunicorn:
   ```bash
   gunicorn -w 4 -k uvicorn.workers.UvicornWorker src.interface.api:app
   ```

## Recursos Adicionales

- [Documentaci√≥n de Streamlit](https://docs.streamlit.io/)
- [Documentaci√≥n de OpenAI](https://platform.openai.com/docs/api-reference)
- [Documentaci√≥n de Anthropic](https://docs.anthropic.com/claude/reference/getting-started-with-the-api)
- [Gu√≠a de estilo PEP 8](https://peps.python.org/pep-0008/)
- [Documentaci√≥n de pytest](https://docs.pytest.org/)